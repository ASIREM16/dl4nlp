{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.1: Named entity recognition\n",
    "\n",
    "In this exercise, we will implement a named entity recognition system using a few different neural models. This example uses training and validation data from the [CoNLL-2003 Shared Task](https://www.clips.uantwerpen.be/conll2003/ner/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this notebook less cluttered, we move some utilities for preprocessing, batch management, and evaluation into a separate Python file `ner_util.py`.\n",
    "\n",
    "The main utilities in this file are:\n",
    "* `read_data` for reading the dataset,\n",
    "* `Vocabulary` for managing the vocabulary,\n",
    "* `SequenceDataset` and `SequenceBatcher` for managing minibatches,\n",
    "* `load_gensim_vectors` for loading pre-trained word embeddings via [gensim](https://radimrehurek.com/gensim/),\n",
    "* `evaluate_bio` for computing evaluation scores for the predicted entities,\n",
    "* `show_entities` for printing sentences and their entities in a nice format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ner_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "The training, validation and testing data can be downloaded from the following site:\n",
    "\n",
    "http://demo.spraakdata.gu.se/richard/dl4nlp/ex2_1/\n",
    "\n",
    "The username and password are both `waspnlp`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note about the format. The dataset consists of tokenized sentences. Each row corresponds to one token, and for each token there is a word a number of annotations, separated by whitespace. The sentences are separated by empty lines. Here is an example of a sentence.\n",
    "```\n",
    "United   NNP B-NP B-ORG\n",
    "Nations  NNP I-NP I-ORG\n",
    "official NN  I-NP O\n",
    "Ekeus    NNP B-NP B-PER\n",
    "heads    VBZ B-VP O\n",
    "for      IN  B-PP O\n",
    "Baghdad  NNP B-NP B-LOC\n",
    ".        .   O    O\n",
    "```\n",
    "In this exercise, we will just use the first and last columns: the words and the BIO-coded named entity labels. (The second and third columns contain part-of-speech tags and phrase labels, but we will ignore them.)\n",
    "\n",
    "The utility function `read_data` reads a file and returns the words and BIO labels for all sentences in a file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Getting started with a baseline model for sequence labeling\n",
    "\n",
    "We first define the neural network model.\n",
    "\n",
    "Our first model is simplistic and will be extended later. To predict the output BIO tag for a word, this model applies an embedding and an output unit and it does not consider the context of the word. As we have seen in one of the lectures, this is likely to work quite poorly since words may behave differently in different contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSequenceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_emb_layer, n_labels):\n",
    "        super().__init__()                \n",
    "\n",
    "        # The model consists of just a word embedding layer and a\n",
    "        # linear output unit. The embedding layer has already been created elsewhere.        \n",
    "        self.word_embedding = word_emb_layer\n",
    "        \n",
    "        word_emb_dim = word_emb_layer.weight.shape[1]\n",
    "        \n",
    "        self.top_layer = nn.Linear(word_emb_dim, n_labels)\n",
    "                        \n",
    "    def forward(self, words):\n",
    "        # words is a tensor of integer-encoded words, with shape (n_sentences, n_words)\n",
    "                \n",
    "        # After embedding the words, the shape is (n_sentences, n_words, emb_dim). \n",
    "        word_repr = self.word_embedding(words)\n",
    "            \n",
    "        # We predict the BIO label simply by applying a linear model to\n",
    "        # the word embedding at that position.\n",
    "        \n",
    "        # The shape of the output is (n_sentences, n_words, n_labels),\n",
    "        # where n_labels is the size of the output label vocabulary.\n",
    "        return self.top_layer(word_repr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the complete the system\n",
    "\n",
    "We can now assemble all the pieces and build a complete named entity recognition system, implemented in the class `SequenceLabeler`. \n",
    "\n",
    "The interesting part here is the method `train`, which carries out the preprocessing steps, sets up the neural network defined above, and then runs the training loop. You should be familiar with the general structure of this kind of programs by now. The comments inside the code explain the details more explicitly.\n",
    "\n",
    "The method `predict` can be used to apply the trained NER system to new sentences.\n",
    "\n",
    "The hyperparameters are stored in a container `SeqLabelerParameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqLabelerParameters:\n",
    "    device = 'cuda'\n",
    "    \n",
    "    random_seed = 0\n",
    "    \n",
    "    train_file = '../data/eng.train.iob'\n",
    "    valid_file = '../data/eng.valid.iob'\n",
    "    \n",
    "    use_characters = True\n",
    "    \n",
    "    word_emb_dim = 128\n",
    "    \n",
    "    pretrained_word_emb = gensim_glove_model\n",
    "    finetune_word_emb = False\n",
    "    \n",
    "    n_epochs = 20\n",
    "    batch_size = 128\n",
    "    \n",
    "    learning_rate = 5e-3\n",
    "    weight_decay = 1e-6\n",
    "    \n",
    "    word_dropout_prob = 0.1\n",
    "    \n",
    "\n",
    "class SequenceLabeler:\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self.params = params        \n",
    "                \n",
    "    def train(self):\n",
    "        \n",
    "        p = self.params\n",
    "        \n",
    "        # Setting a fixed seed for reproducibility.\n",
    "        torch.manual_seed(p.random_seed)\n",
    "        random.seed(p.random_seed)\n",
    "        \n",
    "        # Read training and validation data according to the predefined split.\n",
    "        Xtrain, Ytrain = ner_util.read_data(p.train_file)\n",
    "        Xval, Yval = ner_util.read_data(p.valid_file)\n",
    "                \n",
    "        # Create vocabularies for words and output labels.\n",
    "        self.word_voc = ner_util.Vocabulary(include_unknown=True, gensim_model=p.pretrained_word_emb)\n",
    "        self.label_voc = ner_util.Vocabulary(include_unknown=False)\n",
    "        self.label_voc.build(Ytrain)\n",
    "        \n",
    "        # If we are using a pre-trained word embedding model, then we use its built-in vocabulary;\n",
    "        # otherwise, we build the word vocabulary from the data.\n",
    "        if not p.pretrained_word_emb:\n",
    "            self.word_voc.build(Xtrain)        \n",
    "\n",
    "        # Also create a vocabulary for characters. (Will be used in a later part of the exercise.)\n",
    "        self.char_voc = ner_util.Vocabulary(include_unknown=True, character=True)            \n",
    "        self.char_voc.build(Xtrain)\n",
    "        \n",
    "        # Put the training and validation data into Datasets and DataLoaders for managing minibatches.\n",
    "        self.batcher = ner_util.SequenceBatcher(p.device)        \n",
    "        train_dataset = ner_util.SequenceDataset(self.word_voc.encode(Xtrain),                                        \n",
    "                                        self.label_voc.encode(Ytrain),\n",
    "                                        self.char_voc.encode(Xtrain) if p.use_characters else None,\n",
    "                                        word_dropout_prob=p.word_dropout_prob, \n",
    "                                        word_dropout_id=self.word_voc.get_unknown_idx())\n",
    "        train_loader = DataLoader(train_dataset, p.batch_size, shuffle=True, collate_fn=self.batcher)        \n",
    "        val_dataset = ner_util.SequenceDataset(self.word_voc.encode(Xval), \n",
    "                                      self.label_voc.encode(Yval),\n",
    "                                      self.char_voc.encode(Xval) if p.use_characters else None)\n",
    "        val_loader = DataLoader(val_dataset, p.batch_size, shuffle=False, collate_fn=self.batcher)\n",
    "        \n",
    "        \n",
    "        # Now, let's build the model!\n",
    "\n",
    "        # First, we create a word embedding layer. We use another utility function for that (in\n",
    "        # the Vocabulary object). The reason we are doing it in this way is just to simplify our\n",
    "        # work if we want to use pre-trained embeddings later on.\n",
    "        # For now, this will just build a straightforward nn.Embedding and return it.\n",
    "        emb_layer = self.word_voc.make_embedding_layer(finetune=p.finetune_word_emb, \n",
    "                                                       emb_dim=p.word_emb_dim)\n",
    "    \n",
    "        # Create the sequence labeling neural network defined above.\n",
    "        #self.model = SimpleSequenceModel(emb_layer, n_labels=len(self.label_voc))\n",
    "        #self.model = WindowSequenceModel(emb_layer, n_labels=len(self.label_voc))\n",
    "        #self.model = RNNSequenceModel(emb_layer, n_labels=len(self.label_voc),\n",
    "        #                              rnn_size=128, rnn_depth=1)\n",
    "        self.model = RNNCharSequenceModel(emb_layer, n_labels=len(self.label_voc),\n",
    "                                          rnn_size=128, rnn_depth=1,\n",
    "                                          char_emb_dim=16, char_voc_size=len(self.char_voc))\n",
    "        \n",
    "        self.model.to(p.device)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), \n",
    "                                     lr=p.learning_rate, weight_decay=p.weight_decay)\n",
    "\n",
    "        # Cross-entropy loss function that we will use to optimize the model.\n",
    "        # In particular, note that by using ignore_index, we will not compute the loss \n",
    "        # for the positions where we have a padding token.\n",
    "        loss_func = torch.nn.CrossEntropyLoss(ignore_index=self.label_voc.get_pad_idx())\n",
    "        \n",
    "        history = defaultdict(list)\n",
    "                            \n",
    "        for i in range(p.n_epochs):\n",
    "\n",
    "            t0 = time.time()\n",
    "\n",
    "            loss_sum = 0\n",
    "\n",
    "            self.model.train()\n",
    "            for Xbatch_words, Ybatch, Xbatch_chars in train_loader:\n",
    "                                                \n",
    "                # Compute the output scores.\n",
    "                scores = self.model(Xbatch_words, Xbatch_chars)\n",
    "                \n",
    "                # The scores tensor has the shape (n_sentences, n_words, n_labels).\n",
    "                # We reshape this to (n_sentences*n_words, n_labels) because the loss requires\n",
    "                # a 2-dimensional tensor. Similar for the gold standard label tensor.                \n",
    "                loss = loss_func(scores.view(-1, len(self.label_voc)), Ybatch.view(-1))\n",
    "                    \n",
    "                optimizer.zero_grad()            \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_sum += loss.item()\n",
    "\n",
    "            train_loss = loss_sum / len(train_loader)\n",
    "            history['train_loss'].append(train_loss)\n",
    "            \n",
    "            # Evaluate on the validation set.\n",
    "            stats = defaultdict(Counter)\n",
    "\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                for Xbatch_words, Ybatch, Xbatch_chars in val_loader:\n",
    "                    scores = self.model(Xbatch_words, Xbatch_chars)\n",
    "                    \n",
    "                    # Compute the highest-scoring labels at each word position.\n",
    "                    predicted = scores.argmax(dim=2)\n",
    "                    \n",
    "                    # Update the evaluation statistics for this batch.\n",
    "                    ner_util.evaluate_iob(Xbatch_words, predicted, Ybatch, self.label_voc, stats)\n",
    "\n",
    "            # Compute the overall F-score for the validation set.\n",
    "            _, _, val_f1 = ner_util.prf(stats['total'])\n",
    "\n",
    "            history['val_f1'].append(val_f1)\n",
    "\n",
    "            t1 = time.time()\n",
    "            print(f'Epoch {i+1}: train loss = {train_loss:.4f}, val f1: {val_f1:.4f}, time = {t1-t0:.4f}')\n",
    "           \n",
    "        # After the final evaluation, we print more detailed evaluation statistics, including\n",
    "        # precision, recall, and F-scores for the different types of named entities.\n",
    "        print()\n",
    "        print('Final evaluation on the validation set:')\n",
    "        p, r, f1 = ner_util.prf(stats['total'])\n",
    "        print(f'Overall: P = {p:.4f}, R = {r:.4f}, F1 = {f1:.4f}')\n",
    "        for label in stats:\n",
    "            if label != 'total':\n",
    "                p, r, f1 = ner_util.prf(stats[label])\n",
    "                print(f'{label:4s}: P = {p:.4f}, R = {r:.4f}, F1 = {f1:.4f}')\n",
    "        \n",
    "        self.stats = stats\n",
    "        \n",
    "        plt.plot(history['train_loss'])\n",
    "        plt.plot(history['val_f1'])\n",
    "        plt.legend(['training loss', 'validation F-score'])\n",
    "\n",
    "        \n",
    "    def predict(self, sentences):\n",
    "        # This method applies the trained model to a list of sentences.\n",
    "        \n",
    "        Ydummy = [[self.label_voc.itos[0]]*len(sen) for sen in sentences]\n",
    "            \n",
    "        dataset = ner_util.SequenceDataset(self.word_voc.encode(sentences), \n",
    "                                  self.label_voc.encode(Ydummy),\n",
    "                                  self.char_voc.encode(sentences))\n",
    "        loader = DataLoader(dataset, self.params.batch_size, shuffle=False, collate_fn=self.batcher)\n",
    "                \n",
    "        out = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for Xbatch_words, _, Xbatch_chars in loader:\n",
    "                \n",
    "                scores = self.model(Xbatch_words, Xbatch_chars)                   \n",
    "                predicted = scores.argmax(dim=2) \n",
    "                \n",
    "                # Convert the integer-encoded tags to tag strings.\n",
    "                for pred_sen in predicted.cpu().numpy():\n",
    "                    tokens = sentences[len(out)]\n",
    "                    out.append([self.label_voc.itos[pred_id] for _, pred_id in zip(tokens, pred_sen[1:])])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the complete system. The training loop will compute the loss during each epoch, and then compute the F-score (the harmonic mean of precision and recall) on the validation set.\n",
    "\n",
    "After completing the training process, we get some more detailed evaluation results, where you can see precision, recall, and F-scores for all types of entities. After 10 epochs with the default system, we get an F-score of about 0.60, so the system has learned to pick up some named entities although it is far from perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 0.2716, val f1: 0.8414, time = 4.0089\n",
      "Epoch 2: train loss = 0.0791, val f1: 0.8767, time = 4.2544\n",
      "Epoch 3: train loss = 0.0615, val f1: 0.9012, time = 3.9761\n",
      "Epoch 4: train loss = 0.0508, val f1: 0.9041, time = 3.9798\n",
      "Epoch 5: train loss = 0.0416, val f1: 0.9166, time = 3.7183\n",
      "Epoch 6: train loss = 0.0337, val f1: 0.9146, time = 4.0349\n",
      "Epoch 7: train loss = 0.0301, val f1: 0.9142, time = 4.0020\n",
      "Epoch 8: train loss = 0.0272, val f1: 0.9172, time = 4.0083\n",
      "Epoch 9: train loss = 0.0229, val f1: 0.9138, time = 3.9902\n",
      "Epoch 10: train loss = 0.0213, val f1: 0.9114, time = 4.0286\n",
      "Epoch 11: train loss = 0.0191, val f1: 0.9190, time = 4.0283\n",
      "Epoch 12: train loss = 0.0164, val f1: 0.9198, time = 3.9831\n",
      "Epoch 13: train loss = 0.0156, val f1: 0.9201, time = 4.0151\n",
      "Epoch 14: train loss = 0.0152, val f1: 0.9168, time = 4.0092\n",
      "Epoch 15: train loss = 0.0149, val f1: 0.9175, time = 4.0405\n",
      "Epoch 16: train loss = 0.0180, val f1: 0.9197, time = 4.0331\n",
      "Epoch 17: train loss = 0.0123, val f1: 0.9208, time = 4.2192\n",
      "Epoch 18: train loss = 0.0126, val f1: 0.9154, time = 4.0755\n",
      "Epoch 19: train loss = 0.0128, val f1: 0.9174, time = 4.0750\n",
      "Epoch 20: train loss = 0.0143, val f1: 0.9193, time = 4.0477\n",
      "\n",
      "Final evaluation on the validation set:\n",
      "Overall: P = 0.9114, R = 0.9275, F1 = 0.9193\n",
      "ORG : P = 0.8722, R = 0.8956, F1 = 0.8837\n",
      "LOC : P = 0.9413, R = 0.9516, F1 = 0.9464\n",
      "MISC: P = 0.8291, R = 0.8525, F1 = 0.8406\n",
      "PER : P = 0.9523, R = 0.9642, F1 = 0.9582\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_system = SequenceLabeler(SeqLabelerParameters())\n",
    "ner_system.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out some examples\n",
    "\n",
    "Let's consider some examples and try to understand how the system behaves.\n",
    "\n",
    "As mentioned above, we can call `predict` to get the system's predictions for a new text. The text needs to be split into sentences and tokens. The corresponding BIO labels will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B-PER', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_system.predict(['Jane lives in New York City .'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a utility function `show_entities` that shows the sentence and the entities in a colored format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size:150%; line-height: 150%;\"><div> <b style=\"background-color: #aaaaff; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>PER</tt></sup> Jane</b> lives in <b style=\"background-color: #aaffaa; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>LOC</tt></sup> New York City</b> .</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_util.show_entities(ner_system, ['Jane lives in New York City .'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets more interesting when we include some words that should be tagged differently depending on the context. Here, we can clearly see the limitations of our current model. (In the second example, we'd like *Manchester* to be an organization in the first case and a location in the second case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size:150%; line-height: 150%;\"><div> <b style=\"background-color: #ff8800; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>ORG</tt></sup> Manchester United</b> will return to the <b style=\"background-color: #aaffaa; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>LOC</tt></sup> United States</b> .</div><div> <b style=\"background-color: #ff8800; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>ORG</tt></sup> Manchester</b> scored against <b style=\"background-color: #ff8800; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>ORG</tt></sup> Liverpool</b> when they were playing in <b style=\"background-color: #aaffaa; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>LOC</tt></sup> Manchester</b> .</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_util.show_entities(ner_system, ['Manchester United will return to the United States .'.split(),\n",
    "                                    'Manchester scored against Liverpool when they were playing in Manchester .'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also note that the system generalizes poorly when we encounter words that have not been observed in the training set. Our system does not find any names in the example below, but as human readers, we don't have a problem to understand that *Tarakanov* is a person and *Lüneburg* is a location.\n",
    "\n",
    "For instance, we might already know from prior experience that *Tarakanov* is a surname, or we can deduce this because of the *-ov* suffix or because the context makes it likely that this is a person. Similarly, we might have heard about *Lüneburg* (a city in Germany) before, or we guess that this is a place because of the context or the *-burg* suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size:150%; line-height: 150%;\"><div> Tarakanov lives in Lüneburg .</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_util.show_entities(ner_system, ['Tarakanov lives in Lüneburg .'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Window-based sequence labeling\n",
    "\n",
    "Our first model works poorly because it does not take the surrounding words into account when predicting the output labels. So let's simply build a second prediction model that not only looks at a single word in isolation, but also considers one word before and one word after.\n",
    "\n",
    "<img src=\"http://www.cse.chalmers.se/~richajo/waspnlp2020/ex2_1/ffwin_simpler.svg\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "**Hint**: To save you some time in the exercise, here is some code that might be useful when you compute the representations of the three-word windows. We assume that we have computed a word embedding tensor `word_repr` for our batch as in the code above, which will then have the shape `(n_sentences, n_words, emb_dim)`.\n",
    "\n",
    "We can then create a tensor `before_word_repr` that contains word embeddings shifted one step backward, and another tensor `after_word_repr` where the embeddings have been shifted one step forward. We insert some zero padding so that these tensors will have the same shape as `word_repr`.\n",
    "\n",
    "    n_sent, _, emb_dim = word_repr.shape\n",
    "    zero_pad = torch.zeros(n_sent, 1, emb_dim, device=word_reps.device)\n",
    "    word_before_repr = torch.cat([zero_pad, word_repr[:,:-1,:]], dim=1)\n",
    "    word_after_repr = torch.cat([word_repr[:,1:,:], zero_pad], dim=1)\n",
    "\n",
    "Then \"glue\" the three word embedding tensors together using `torch.cat` so that you get a tensor representing the 3-word windows. This will then have the shape `(n_sentences, n_words, 3*emb_dim)`.\n",
    "\n",
    "Finally, modify the output unit to reflect this change and rerun the code. Do the scores improve? How about the test cases above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** Solution ***\n",
    "\n",
    "My validation F-score is 0.7947, up from 0.64. `n_epochs` was increased to 20, all other hyperparameters unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowSequenceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_emb_layer, n_labels):\n",
    "        super().__init__()                \n",
    "        self.word_embedding = word_emb_layer\n",
    "        word_emb_dim = word_emb_layer.weight.shape[1]\n",
    "        self.top_layer = nn.Linear(3*word_emb_dim, n_labels)\n",
    "                        \n",
    "    def forward(self, words):\n",
    "        word_repr = self.word_embedding(words)\n",
    "        \n",
    "        n_sent, _, emb_dim = word_repr.shape\n",
    "        zero_pad = torch.zeros(n_sent, 1, emb_dim, device=word_repr.device)\n",
    "        word_before_repr = torch.cat([zero_pad, word_repr[:,:-1,:]], dim=1)\n",
    "        word_after_repr = torch.cat([word_repr[:,1:,:], zero_pad], dim=1)\n",
    "        \n",
    "        # combine the 3 embedding tensors\n",
    "        window_repr = torch.cat([word_before_repr, word_repr, word_after_repr], dim=2)\n",
    "        \n",
    "        return self.top_layer(window_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can improve some of the test cases above. The example with the unknown words still doesn't give anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size:150%; line-height: 150%;\"><div> <b style=\"background-color: #ff8800; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>ORG</tt></sup> Manchester United</b> will return to the <b style=\"background-color: #aaffaa; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>LOC</tt></sup> United States</b> .</div><div> <b style=\"background-color: #ff8800; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>ORG</tt></sup> Manchester</b> scored against <b style=\"background-color: #ff8800; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>ORG</tt></sup> Liverpool</b> when they were playing in <b style=\"background-color: #aaffaa; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>LOC</tt></sup> Manchester</b> .</div><div> Tarakanov lives in Lüneburg .</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_util.show_entities(ner_system, ['Manchester United will return to the United States .'.split(),\n",
    "                                    'Manchester scored against Liverpool when they were playing in Manchester .'.split(),\n",
    "                                    'Tarakanov lives in Lüneburg .'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. RNN-based sequence labeling\n",
    "\n",
    "The window-based prediction model is limited in its representation capabilities by the width of the window, so let's try to use a RNN-based representation, which does not have this limitation. The following figure gives you an idea of the type of model we should try to build: \n",
    "\n",
    "<img src=\"http://www.cse.chalmers.se/~richajo/waspnlp2020/ex2_1/rnn_seq_ner.svg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "**Hint 1**: The code to build the model and the `forward` step will probably be quite similar to what you wrote in the language modeling exercise.\n",
    "\n",
    "**Hint 2**: a bidirectional RNN will probably be more useful than the model in the figure. Any idea why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** Solution ***\n",
    "\n",
    "My validation F-score is 0.8420 with 15 epochs, and a bidirectional GRU of depth 1 and a size of 128. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNSequenceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_layer, n_labels, rnn_size, rnn_depth):\n",
    "        super().__init__()\n",
    "        self.embedding = emb_layer\n",
    "        word_dim = emb_layer.weight.shape[1]\n",
    "        \n",
    "        # RNN layer. We're using a bidirectional GRU.\n",
    "        self.rnn = nn.GRU(batch_first=True, input_size=word_dim, hidden_size=rnn_size, \n",
    "                          bidirectional=True, num_layers=rnn_depth)\n",
    "        #self.rnn = nn.LSTM(batch_first=True, input_size=word_dim, hidden_size=rnn_size, \n",
    "        #                   bidirectional=True, num_layers=1)\n",
    "\n",
    "        # Output layer. The input size is two times\n",
    "        # the RNN size since we are using a bidirectional RNN.\n",
    "        self.top_layer = nn.Linear(2*rnn_size, n_labels)\n",
    "              \n",
    "            \n",
    "    def forward(self, words):\n",
    "        # input shape: (n_seqs, max_len)\n",
    "        \n",
    "        # shape: (n_seqs, max_len, emb_dim). \n",
    "        word_repr = self.embedding(words)\n",
    "                        \n",
    "        # shape: (n_seqs, max_len, 2*rnn_size)\n",
    "        rnn_out, _ = self.rnn(word_repr)\n",
    "        \n",
    "        # output shape: (n_seqs, max_len, n_labels)\n",
    "        return self.top_layer(rnn_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a problem with unseen words. For the example above and those in the next section, we see that we can't find any names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size:150%; line-height: 150%;\"><div> Tarakanov lives in Lüneburg .</div><div> Linköping is nice .</div><div> Judy is nice</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_util.show_entities(ner_system, ['Tarakanov lives in Lüneburg .'.split(),\n",
    "                                    'Linköping is nice .'.split(),\n",
    "                                    'Judy is nice'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Pre-trained word embeddings\n",
    "\n",
    "How can we deal with names that we haven't seen before? For instance, in the following examples, the names are not present in the training set, and the context doesn't give us much information:\n",
    "\n",
    "    Linköping is nice.\n",
    "    Judy is nice.\n",
    "\n",
    "Currently, since *Linköping* and *Judy* haven't been seen before, their representations will be identical, since we will use a generic \"unknown word\" embedding in these cases. Pre-trained word embeddings may help us here: while *Linköping* is not present in our training set, it is distributionally similar to names of other cities, and this might help us to assign the correct label `B-LOC`.\n",
    "\n",
    "The [gensim](https://radimrehurek.com/gensim/) library includes a number of built-in word embedding models. You can find a list of them here:\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim-data#models\n",
    "\n",
    "The utility function `load_gensim_vectors` loads a pre-trained word embedding model and converts it into a PyTorch tensor. Gensim will automatically download the file (which will take some minutes the first time). For instance:\n",
    "\n",
    "    gensim_glove_model = ner_util.load_gensim_vectors('glove-wiki-gigaword-100', builtin=True)\n",
    "\n",
    "Here, `glove-wiki-gigaword-100` is the name of the model, and `builtin=True` shows that we are using one of the library's built-in models (and not a file of our own).\n",
    "\n",
    "Load one of gensim's pre-trained models. Then, in the hyperparameter settings defined above, change `pretrained_word_emb = None` to the embedding model you loaded. Retrain the model and see if this improves the results. Can the system handle the problematic examples above now?\n",
    "\n",
    "**Hint**: it might be useful to investigate whether the word embedding model should be *fine-tuned* or not. This can be controlled via the hyperparameter `finetune_word_emb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** Solution: ***\n",
    "\n",
    "The F-score is now 0.8839. Everything is identical to the previous RNN-based model, except that we're using the pre-trained model and that we disabled word embedding fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 'glove-wiki-gigaword-100' via gensim... done!\n"
     ]
    }
   ],
   "source": [
    "gensim_glove_model = ner_util.load_gensim_vectors('glove-wiki-gigaword-100', builtin=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be able to handle at least some of the previously unseen words. (In my solution, 3 out of four names in these examples are handled correctly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size:150%; line-height: 150%;\"><div> <b style=\"background-color: #aaaaff; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>PER</tt></sup> Tarakanov</b> lives in <b style=\"background-color: #aaffaa; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>LOC</tt></sup> Lüneburg</b> .</div><div> <b style=\"background-color: #aaffaa; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>LOC</tt></sup> Linköping</b> is nice .</div><div> <b style=\"background-color: #aaaaff; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>PER</tt></sup> Judy</b> is nice</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_util.show_entities(ner_system, ['Tarakanov lives in Lüneburg .'.split(),\n",
    "                                    'Linköping is nice .'.split(),\n",
    "                                    'Judy is nice'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Character-based word representation\n",
    "\n",
    "Although we have improved the coverage by using the pre-trained word embeddings, the model still lacks a way to generalize in a way that takes word properties into account. For instance, as mentioned in the lecture, many Swedish surnames end in *-sson*, which could help us deduce that such strings are person names. Or on a more basic level, we may observe that an initial upper-case letter makes it more likely that a word is a name. By introducing a *character-based* word representation, our model might learn to generalize in this way.\n",
    "\n",
    "The following figure gives you an idea of what we would like to implement:\n",
    "\n",
    "<img src=\"http://www.cse.chalmers.se/~richajo/waspnlp2020/ex2_1/char_repr.svg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "The \"something\" in this figure could be implemented in different ways:\n",
    "\n",
    "* In [*Neural Architectures for Named Entity Recognition*](https://www.aclweb.org/anthology/N16-1030.pdf) by Lample et al. (2016), a bidirectional RNN is applied to the characters. (See Figure 4.)\n",
    "* In [*End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF*](https://www.aclweb.org/anthology/P16-1101.pdf) by Ma and Hovy (2016), a convolutional layer and pooling is used. (See Figure 1.)\n",
    "\n",
    "To work with characters in our code, first set the hyperparameter `use_characters` to `True`. By enabling this option, we will include character tensors in each minibatch. (That is, `Xbatch_chars` in the training loop will be non-empty.)\n",
    "\n",
    "Then create a new model where the `forward` method takes the word and character tensors as the input, and implement a word representation approach that combines word embeddings with a character-based representation. Do you get better F-scores now? Also try to think of some test cases where it might be useful to take the word structure into account and investigate if your model can handle them better now than before.\n",
    "\n",
    "**Hints**:\n",
    "* RNN and CNN layers expect three-dimensional inputs. The character tensor in each batch has the shape `(n_sentences, n_words, n_characters)`, so you will likely have to reshape it into `(n_sentences*n_words, n_characters)` to get a 3-dimensional structure after embedding the characters.\n",
    "* If you'd like to implement Lample's RNN-based architecture, you might have something like the following:\n",
    "```\n",
    "    _, (final_state, _) = char_rnn(character_embedding)  # if char_rnn is an LSTM\n",
    "    _, final_state      = char_rnn(character_embedding)  # if char_rnn is a GRU\n",
    "``` \n",
    "  In this case, `final_state` will be a tensor with the shape `(n_layers, batch_size, rnn_size)`. It contains the final RNN states in each layer for every sequence in the batch. To follow Lample's approach, you can extract the last two \"rows\" in this tensor.\n",
    "* For a CNN-based solution as in Ma's architecture, you should use a one-dimensional convolution (`nn.Conv1d`) followed by a pooling operation. Note that the convolution is computed over the last dimension of the tensor, so you might need to transpose the tensor to put the character dimension last: `character_embedding.transpose(1, 2)`. To carry out a pooling operation over the entire sequence, you can use *adaptive* pooling layers, e.g. `nn.AdaptiveMaxPool1d(1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** Solution ***\n",
    "\n",
    "I tried out 3 different solutions (implementations below). The performance scores of these models seem to be more or less equivalent and they all reach F-scores of around 0.92.\n",
    "\n",
    "With the Lample-like RNN-based representation, my F-score is 0.9193. The hyperparameters are the same as previously, except that `n_epochs` was set to 20 and the word dropout rate set to 0.1. The character embedding size (and character RNN size) was set to 16.\n",
    "\n",
    "With this implementation, we can find all the names in the tricky test cases we tried previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size:150%; line-height: 150%;\"><div> <b style=\"background-color: #aaaaff; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>PER</tt></sup> Tarakanov</b> lives in <b style=\"background-color: #aaffaa; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>LOC</tt></sup> Lüneburg</b> .</div><div> <b style=\"background-color: #aaffaa; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>LOC</tt></sup> Linköping</b> is nice .</div><div> <b style=\"background-color: #aaaaff; color: black; border-radius: 3px; padding: 3px;\"><sup style=font-size:small;><tt>PER</tt></sup> Judy</b> is nice</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ner_util.show_entities(ner_system, ['Tarakanov lives in Lüneburg .'.split(),\n",
    "                                    'Linköping is nice .'.split(),\n",
    "                                    'Judy is nice'.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** RNN-based solution ***\n",
    "\n",
    "Similar to Lample et al. (2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCharSequenceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_layer, n_labels, rnn_size, rnn_depth, char_voc_size, char_emb_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = emb_layer\n",
    "        \n",
    "        word_dim = emb_layer.weight.shape[1]\n",
    "\n",
    "        # Character embedding.\n",
    "        self.char_embedding = nn.Embedding(char_voc_size, char_emb_dim)\n",
    "        \n",
    "        # Character RNN. It's bidirectional with 1 layer as in Lample's paper.\n",
    "        self.char_rnn = nn.GRU(input_size=char_emb_dim, hidden_size=char_emb_dim, batch_first=True,\n",
    "                               bidirectional=True, num_layers=1)\n",
    "        word_dim += 2*char_emb_dim\n",
    "        \n",
    "        self.rnn = nn.GRU(batch_first=True, input_size=word_dim, hidden_size=rnn_size, \n",
    "                          bidirectional=True, num_layers=rnn_depth)\n",
    "        self.top_layer = nn.Linear(2*rnn_size, n_labels)\n",
    "              \n",
    "            \n",
    "    def forward(self, words, chars):\n",
    "        n_sent, n_words, n_chars = chars.shape\n",
    "        \n",
    "        # The shape of the embedded word tensor is (n_sent, n_words, emb_dim). \n",
    "        word_repr = self.embedding(words)\n",
    "            \n",
    "        # Reshape the character tensor so that we get a 3-dimensional tensor after embedding.\n",
    "        chars = chars.view(n_sent*n_words, n_chars)\n",
    "\n",
    "        # Look up character embeddings. The shape is now \n",
    "        # (n_sent*n_words, n_chars, char_emb_dim).        \n",
    "        char_emb = self.char_embedding(chars)\n",
    "\n",
    "        # Compute the final RNN states. This tensor has the \n",
    "        # shape (n_layers, n_sent*n_words, char_emb_dim).\n",
    "\n",
    "        # If you use a GRU or simple RNN for the character RNN:\n",
    "        _, final_state = self.char_rnn(char_emb)\n",
    "        # if you use an LSTM for the character RNN:\n",
    "        #_, (final_state, _) = self.char_rnn(char_emb)\n",
    "\n",
    "        # Extract the final states from the highest forward and backward RNN layer.\n",
    "        # Reshape these tensor to (n_sent, n_words, char_emb_dim).\n",
    "        crnn_forward = final_state[-2].view(n_sent, n_words, -1)\n",
    "        crnn_backward = final_state[-1].view(n_sent, n_words, -1)\n",
    "\n",
    "        # Combine the word embeddings with character-based representations.\n",
    "        # Shape: (n_sent, n_words, word_emb_dim+2*char_emb_dim).\n",
    "        word_repr = torch.cat([word_repr, crnn_forward, crnn_backward], dim=2)\n",
    "            \n",
    "        rnn_out, _ = self.rnn(word_repr)\n",
    "        return self.top_layer(rnn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** CNN-based solution ***\n",
    "\n",
    "Similar to Ma and Hovy (2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCharCNNSequenceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_layer, n_labels, rnn_size, rnn_depth, char_voc_size, char_emb_dims):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = emb_layer\n",
    "        \n",
    "        word_dim = emb_layer.weight.shape[1]\n",
    "\n",
    "        # Character embedding.\n",
    "        self.char_embedding = nn.Embedding(char_voc_size, char_emb_dim)            \n",
    "        # Convolutional layer. We use the same output dimension as the character embedding.         \n",
    "        self.char_cnn = nn.Conv1d(in_channels=char_emb_dim, out_channels=char_emb_dim, \n",
    "                                  kernel_size=2)\n",
    "        # Max pooling over the whole word (number of pooling regions = 1).\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        word_dim += char_emb_dim\n",
    "        \n",
    "        self.rnn = nn.GRU(batch_first=True, input_size=word_dim, hidden_size=rnn_size, \n",
    "                          bidirectional=True, num_layers=rnn_depth)\n",
    "\n",
    "        self.top_layer = nn.Linear(2*rnn_size, n_labels)\n",
    "              \n",
    "            \n",
    "    def forward(self, words, chars):\n",
    "        n_sent, n_words, n_chars = chars.shape\n",
    "        \n",
    "        # The shape of the embedded word tensor is (n_sent, n_words, emb_dim). \n",
    "        word_repr = self.embedding(words)\n",
    "\n",
    "        # Reshape the character tensor.\n",
    "        chars = chars.view(n_sent*n_words, n_chars)\n",
    "\n",
    "        # Look up character embeddings. The shape is now \n",
    "        # (n_sent*n_words, n_chars, char_emb_dim).\n",
    "        char_emb = self.char_embedding(chars)\n",
    "\n",
    "        # Flip the character embedding tensor so that the character position dimension\n",
    "        # goes last. The convolution runs over the last dimension.\n",
    "        char_emb = char_emb.permute(0, 2, 1)\n",
    "\n",
    "        # Apply the convolution.\n",
    "        conv_out = self.char_cnn(char_emb)\n",
    "\n",
    "        # And then the pooling. The shape is now \n",
    "        # (n_sent*n_words, char_emb_dim, 1).\n",
    "        pooled = self.pool(conv_out)\n",
    "\n",
    "        # Reshape this tensor so that we can \"glue\" it to the word embedding tensor.\n",
    "        # The shape is now (n_sent, n_words, char_emb_dim).\n",
    "        pooled = pooled.view(n_sent, n_words, -1)\n",
    "\n",
    "        # Combine the word embeddings with character-based representations.\n",
    "        # Shape: (n_sent, n_words, word_emb_dim+char_emb_dim).\n",
    "        word_repr = torch.cat([word_repr, pooled], dim=2)\n",
    "            \n",
    "        rnn_out, _ = self.rnn(word_repr)\n",
    "        return self.top_layer(rnn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** RNN with attention ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, rnn_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # This is the neural network that computes the attention scores.\n",
    "        # To keep things simple, we'll use a linear model here.\n",
    "        self.attn_nn = nn.Linear(rnn_size, 1)\n",
    "        \n",
    "    def forward(self, rnn_output):        \n",
    "        # The input to the attention model is the output from the top layer of the RNN,\n",
    "        # which is a tensor containing the states for each character in each word.\n",
    "        # The shape of this tensor is (n_words, n_chars, rnn_dim).\n",
    "        \n",
    "        # First, we apply the attention neural network to each state in the RNN output.\n",
    "        e = self.attn_nn(rnn_output)\n",
    "                \n",
    "        # The shape is now (n_words, n_chars, 1). The squeeze method will reshape\n",
    "        # the tensor to (n_words, n_chars).\n",
    "        e = e.squeeze()\n",
    "        \n",
    "        # Compute attention weights by applying the softmax over the character positions.\n",
    "        # This tensor has the same shape as e.\n",
    "        alpha = torch.softmax(e, dim=1)\n",
    "        \n",
    "        # We scale each RNN output by its attention weight.\n",
    "        # In order to carry out the element-wise multiplication, we need to \"flip\"\n",
    "        # the tensor so that the RNN output dimension comes first.\n",
    "        # This tensor has the shape (rnn_dim, n_words, n_chars).        \n",
    "        weighted = alpha * rnn_output.permute(2, 0, 1)\n",
    "                        \n",
    "        # Compute a weighted sum of the RNN output vectors. We sum over the character dimension.\n",
    "        # The shape is now (rnn_dim, n_words).\n",
    "        out = weighted.sum(dim=2)\n",
    "                \n",
    "        # \"Flip\" the tensor back to the shape (n_words, rnn_dim).\n",
    "        return out.t()\n",
    "        \n",
    "class RNNCharAttnSequenceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_layer, n_labels, rnn_size, rnn_depth, char_voc_size, char_emb_dim):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = emb_layer\n",
    "        \n",
    "        word_dim = emb_layer.weight.shape[1]\n",
    "\n",
    "        # Same RNN structure as above.\n",
    "        self.char_embedding = nn.Embedding(char_voc_size, char_emb_dim)            \n",
    "        self.char_rnn = nn.GRU(input_size=char_emb_dim, hidden_size=char_emb_dim, batch_first=True,\n",
    "                               bidirectional=True, num_layers=1)\n",
    "        word_dim += 2*char_emb_dim\n",
    "        \n",
    "        # Attention model.\n",
    "        self.char_attn = SimpleAttention(2*char_emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(batch_first=True, input_size=word_dim, hidden_size=rnn_size, \n",
    "                          bidirectional=True, num_layers=rnn_depth)\n",
    "        self.top_layer = nn.Linear(2*rnn_size, n_labels)\n",
    "              \n",
    "            \n",
    "    def forward(self, words, chars):\n",
    "        n_sent, n_words, n_chars = chars.shape\n",
    "        word_repr = self.embedding(words)\n",
    "\n",
    "        chars = chars.view(n_sent*n_words, n_chars)\n",
    "        char_emb = self.char_embedding(chars)\n",
    "\n",
    "        # Compute the RNN outputs at each character position.\n",
    "        # Shape: (n_sent*n_words, n_chars, 2*char_emb_dim).\n",
    "        rnn_out, _ = self.char_rnn(char_emb)\n",
    "\n",
    "        # Apply the attention model to get a weighted sum over the RNN outputs.\n",
    "        # Shape: (n_sent*n_words, 2*char_emb_dim).\n",
    "        attention_out = self.char_attn(rnn_out)\n",
    "        \n",
    "        # Shape: (n_sent, n_words, 2*char_emb_dim).\n",
    "        attention_out = attention_out.view(n_sent, n_words, -1)\n",
    "\n",
    "        # Shape: (n_sent, n_words, word_emb_dim+2*char_emb_dim).\n",
    "        word_repr = torch.cat([word_repr, attention_out], dim=2)\n",
    "\n",
    "        rnn_out, _ = self.rnn(word_repr)\n",
    "        return self.top_layer(rnn_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
