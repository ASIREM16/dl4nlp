# Deep Learning for Natural Language Processing

This is an overview of the PhD-level course Deep Learning for Natural
Language Processing, taught by [Marco
Kuhlmann](https://www.ida.liu.se/~marku61/) and [Richard
Johansson](http://www.cse.chalmers.se/~richajo/).  The course will run
as a distance course in the second half of the Spring term of 2020.

## Goals

The goal is to introduce machine learning techniques used in modern
natural language processing (NLP). Ideally, after finishing this
course, you will have some familiarity with the state of the art in
NLP and you'll be able to understand modern research papers in this
field, and you'll have some practical experience coding up some of the
well-known models.

See also a [separate page](content.md) that describes the content of
the course a bit more extensively.

## Course Literature

Main course book:

Yoav Goldberg, [Neural Network Methods for Natural Language
Processing](https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037). Morgan
Claypool, 2017.  [Pre-print version](https://arxiv.org/abs/1510.00726)

Jacob Eisenstein, [Natural Language
Processing](https://mitpress.mit.edu/books/introduction-natural-language-processing). MIT
Press, 2019.  [Pre-print
version](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)

Much of the content of the course is not described in a book, so we
will also give pointers to research papers and survey articles when
needed.

## Modules

The course consists of the following three modules, each of which
corresponds to roughly one month's work.

The content of each module consists of
* video lectures introducing the important topics
* pointers to literature, some of which is fundamental and some optional
* a set of small programming exercises
* a set of small discussion tasks
* a large assignment where you implement a model and write a technical report

### Module 1: Representation in NLP; categorization tasks

In the first module, we introduce the most important building blocks
used in modern NLP architectures. We will also consider one of the
most fundamental NLP tasks: text categorization.

[Detailed information about ModuleÂ 1](module1.md)

### Module 2: Structured prediction problems in NLP

In the second module, we will focus on NLP tasks where the goal is to
predict a structured object such a sequence or a tree. Applications
include well-known use cases such as named entity recognition and
syntactic parsing.

### Module 3: Generation problems in NLP and research outlook

In the third module, we consider NLP tasks where we want to generate a
text as the output, such as machine translation and summarization. We
will also give quick introduction to some topics that have become
prominent recently, such as model interpretability.
