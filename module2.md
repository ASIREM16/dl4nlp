# Module 2

In the second module, we will focus on NLP tasks where the goal is to predict a structured object such a sequence or a tree. Applications include well-known use cases such as named entity recognition and syntactic parsing.

## Lecture 1

**Form:** <!--Scheduled ???-->

* Overview of structured prediction problems
* Learning and search
* Typical problems, application examples

<!--**Reading:** Eisenstein, chapterÂ 1-->

## Lecture 2

**Form:** Self-study

* Introduction to sequence prediction tasks [[slides](slides/slides-221.pdf)] [[video](https://youtu.be/VCORDrz-Tzs)]
* Simple labeling architectures
* Word and character-based representations

**Reading:** 

## Exercise 1

**Form:** Zoom, date and time TBA

* Named entity recognition 1

## Lecture 3

**Form:** Self-study

* Labeling as structured prediction
* Conditional random fields
* The Viterbi algorithm

**Reading:**

## Exercise 2

**Form:** Zoom, date and time TBA

* Named entity recognition 2

## Lecture 4

**Form:** Self-study

* Introduction to parsing
* Transition-based parsing
* Imitation learning

**Reading:** 

## Lecture 5

**Form:** Self-study

* Factorized parsing
* Minimum spanning tree parsing

**Reading:** 

## Discussion

**Form:** Zoom, date and time TBA

* Introduction to Assignment 2

## Lecture 6

**Form:** Self-study

* More complex structured prediction tasks

**Reading:** 

## Discussion

**Form:** Zoom, date and time TBA

* Project pitch

## Programming assignment

The second programming assignment is dedicated to the task of *dependency parsing*.
     
